services:
  api:
    build: .
    working_dir: /app
    entrypoint: ["/bin/bash", "/app/start.sh"]
    command: []
    env_file:
      - .env
    environment:
      OLLAMA_URL: http://ollama:11434
    ports:
      - "8000:8000"
    volumes:
      - .:/app
    networks:
      - ai_network
    depends_on:
      - db
      - flask

  db:
    image: postgres:16
    environment:
      POSTGRES_DB: ${POSTGRES_DB:-docsia}
      POSTGRES_USER: ${POSTGRES_USER:-docsia_user}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-senha_super_secreta}
    ports:
      - "5432:5432"
    volumes:
      - pgdata:/var/lib/postgresql/data
    networks:
      - ai_network

  flask:
    build: .
    entrypoint: ["python", "/workspace/app.py", "--host", "0.0.0.0", "--port", "5000"]
    command: []
    working_dir: /workspace
    env_file:
      - .env
    environment:
      OLLAMA_URL: http://ollama:11434
    ports:
      - "5001:5000"
    volumes:
      - ..:/workspace
    networks:
      - ai_network
    depends_on:
      - db
      - ollama

  ollama:
    image: ollama/ollama:latest
    ports:
      - "11434:11434"
    volumes:
      - ollama_data:/root/.ollama
    networks:
      - ai_network

  # opcional: se quiser rodar ollama dentro do compose, descomente
  # ollama:
  #   image: ollama/ollama:latest
  #   ports:
  #     - "11434:11434"
  #   volumes:
  #     - ollama_data:/root/.ollama
  #   networks:
  #     - ai_network

networks:
  ai_network:

volumes:
  pgdata:
  ollama_data:
